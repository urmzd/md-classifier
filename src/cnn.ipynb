{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5cc7c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import asyncio\n",
    "import pyppeteer as ptr\n",
    "from typing import Optional\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58ecbddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77ef13d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/urmzd/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/urmzd/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /home/urmzd/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d338a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "PosTag = tuple[str, str]\n",
    "PosTagList = list[PosTag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38f3ffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scraper.\n",
    "async def download_html(browser: ptr.browser.Browser, url: str, selector: str) -> Optional[str]:\n",
    "    page = await browser.newPage()\n",
    "    await page.goto(url, waitUntil=\"load\")\n",
    "    content = await page.querySelector(selector)\n",
    "\n",
    "    html = ''\n",
    "    if content:\n",
    "        html = await page.evaluate('(element) => element.textContent', content)\n",
    "\n",
    "    return html\n",
    "\n",
    "def write_to_resource_target(file_name, content: PosTagList):\n",
    "    with open(file_name, \"w\") as file:\n",
    "        file.write(\",\".join(content))\n",
    "\n",
    "\n",
    "async def get_training_data_from_folder(folder_path: str) -> None:\n",
    "    browser = await ptr.launch(headless=True)\n",
    "    files = glob(folder_path + '/**/*.csv', recursive=True)\n",
    "    \n",
    "    words = dict()\n",
    "    \n",
    "    for file in files:\n",
    "        result = await get_training_data(browser, file)\n",
    "        write_to_resource_target(file, result)\n",
    "        words[file] = result\n",
    "        \n",
    "                \n",
    "    await browser.close()\n",
    "\n",
    "async def get_training_data(browser: ptr.browser.Browser, file_path: str) -> PosTagList:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "\n",
    "    words = []\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        for _, row in df.iterrows():\n",
    "            print(row)\n",
    "            result = await download_html(browser, row[\"link\"], row[\"selector\"])\n",
    "            words.extend(clean_up_words(tokenize(result)))\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a685f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaners.\n",
    "def tokenize(data: str):\n",
    "    tokenized_words = nltk.word_tokenize(data)\n",
    "    tagged_words = nltk.pos_tag(tokenized_words)\n",
    "    return tagged_words\n",
    "\n",
    "def filter_words(x: PosTag, fns: list[Callable[[PosTag], bool]], keep=True) -> bool:\n",
    "    if not keep:\n",
    "        return False\n",
    "    \n",
    "    if fns:\n",
    "        return filter_words(x, fns[1:], keep=fns[0](x))\n",
    "    \n",
    "    return True\n",
    "    \n",
    "def filter_by_duplicate(x: tuple[str, str]) -> bool:\n",
    "    return x[0] != x[1]\n",
    "\n",
    "def filter_by_stop_word(x: tuple[str, str]) -> bool:\n",
    "    return x[0] not in stopwords.words(\"english\")\n",
    "\n",
    "def filter_by_alphabet(x: tuple[str, str]) -> bool:\n",
    "    regex = re.compile(\"^([a-zA-Z]|')+$\")\n",
    "    return regex.match(x[0])\n",
    "            \n",
    "def clean_up_words(words: PosTagList) -> PosTagList:\n",
    "    return list(filter(\n",
    "        lambda x: filter_words(x, [filter_by_duplicate, filter_by_stop_word, filter_by_alphabet]),\n",
    "        words\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e865ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selector                                           #topicText\n",
      "link        https://www.uptodate.com/contents/depression-t...\n",
      "Name: 0, dtype: object\n",
      "selector    #main-content > div:nth-child(1) > div.content...\n",
      "link        https://www.mayoclinic.org/diseases-conditions...\n",
      "Name: 1, dtype: object\n",
      "selector                                     #mw-content-text\n",
      "link        https://simple.wikipedia.org/wiki/Depression_(...\n",
      "Name: 2, dtype: object\n",
      "selector                                         #maincontent\n",
      "link        https://www.nhs.uk/mental-health/conditions/cl...\n",
      "Name: 3, dtype: object\n",
      "selector                   #overview > div > div > section\n",
      "link        https://familydoctor.org/condition/depression/\n",
      "Name: 4, dtype: object\n",
      "selector    #__next > div.css-fdjy12 > div:nth-child(5) > ...\n",
      "link        https://www.healthline.com/health/depression#s...\n",
      "Name: 5, dtype: object\n",
      "selector    #__next > div.css-fdjy12 > div:nth-child(5) > ...\n",
      "link        https://www.medicalnewstoday.com/articles/3213...\n",
      "Name: 6, dtype: object\n",
      "selector                   #skip > div:nth-child(1) > article\n",
      "link        https://www.hopkinsmedicine.org/health/conditi...\n",
      "Name: 7, dtype: object\n",
      "selector    body > div:nth-child(6) > div > div.main-conte...\n",
      "link        https://www.childrenshospital.org/conditions-a...\n",
      "Name: 8, dtype: object\n",
      "selector                                    #mntl-sc-page_1-0\n",
      "link        https://www.verywellmind.com/what-is-moderate-...\n",
      "Name: 9, dtype: object\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../resources/targets/../resources/sources/depression.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7698/3796854438.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mawait\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mget_training_data_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../resources/sources\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_7698/832202800.py\u001b[0m in \u001b[0;36mget_training_data_from_folder\u001b[0;34m(folder_path)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mget_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrowser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mwrite_to_resource_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7698/832202800.py\u001b[0m in \u001b[0;36mwrite_to_resource_target\u001b[0;34m(file_name, content)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwrite_to_resource_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPosTagList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"../resources/targets/{file_name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../resources/targets/../resources/sources/depression.csv'"
     ]
    }
   ],
   "source": [
    "# type: ignore\n",
    "await (get_training_data_from_folder(\"../resources/sources\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc07428",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8b403e565ea1794a437a21eaf7a4df5fa78d6ee8c0957d183a6329de63bb757"
  },
  "kernelspec": {
   "display_name": "mdnlp",
   "language": "python",
   "name": "mdnlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
