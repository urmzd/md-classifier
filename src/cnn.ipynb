{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5cc7c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import asyncio\n",
    "import pyppeteer as ptr\n",
    "from typing import Optional\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from typing import Callable\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ecbddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77ef13d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/urmzd/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/urmzd/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /home/urmzd/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d338a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "PosTag = tuple[str, str]\n",
    "PosTagList = list[PosTag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38f3ffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scraper.\n",
    "async def download_html(browser: ptr.browser.Browser, page: ptr.page.Page, url: str, selector: str) -> Optional[str]:\n",
    "    await page.goto(url, waitUntil=\"load\", timeout=0)\n",
    "    content = await page.querySelector(selector)\n",
    "\n",
    "    html = ''\n",
    "    if content:\n",
    "        html = await page.evaluate('(element) => element.textContent', content)\n",
    "        \n",
    "    return html\n",
    "\n",
    "def write_to_resource_target(file_path: str, content: PosTagList) -> None:\n",
    "    with open(file_path, \"w\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"value\", \"tag\"])\n",
    "        writer.writerows(content)\n",
    "\n",
    "\n",
    "async def get_training_data_from_folder(source_path: str, target_path: str, force=False) -> None:\n",
    "    browser = await ptr.launch(headless=True)\n",
    "    page = await browser.newPage()\n",
    "    \n",
    "    glob_pattern = \"/**/*.csv\"\n",
    "    source_files = glob(source_path + glob_pattern, recursive=True)\n",
    "    target_files = glob(target_path + glob_pattern, recursive=True)\n",
    "    target_file_names = [file_path.split(\"/\")[-1] for file_path in target_files]\n",
    "    \n",
    "    for file_path in source_files:\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "\n",
    "        if not (file_name in target_file_names or force):\n",
    "            result = await get_training_data(browser, page, file_path)\n",
    "            write_to_resource_target(f\"{target_path}/{file_name}\", result)        \n",
    "                \n",
    "    await browser.close()\n",
    "\n",
    "async def get_training_data(browser: ptr.browser.Browser, page: ptr.page.Page, file_path: str) -> PosTagList:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "\n",
    "    words = []\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        for _, row in df.iterrows():\n",
    "            print(row)\n",
    "            result = await download_html(browser, page, row[\"link\"], row[\"selector\"])\n",
    "            words.extend(clean_up_words(tokenize(result)))\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a685f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaners.\n",
    "def tokenize(data: str):\n",
    "    tokenized_words = nltk.word_tokenize(data)\n",
    "    tagged_words = nltk.pos_tag(tokenized_words)\n",
    "    return tagged_words\n",
    "\n",
    "def filter_words(x: PosTag, fns: list[Callable[[PosTag], bool]], keep=True) -> bool:\n",
    "    if not keep:\n",
    "        return False\n",
    "    \n",
    "    if fns:\n",
    "        return filter_words(x, fns[1:], keep=fns[0](x))\n",
    "    \n",
    "    return True\n",
    "    \n",
    "def filter_by_duplicate(x: tuple[str, str]) -> bool:\n",
    "    return x[0] != x[1]\n",
    "\n",
    "def filter_by_stop_word(x: tuple[str, str]) -> bool:\n",
    "    return x[0] not in stopwords.words(\"english\")\n",
    "\n",
    "def filter_by_alphabet(x: tuple[str, str]) -> bool:\n",
    "    regex = re.compile(\"^([a-zA-Z]|')+$\")\n",
    "    return regex.match(x[0])\n",
    "            \n",
    "def clean_up_words(words: PosTagList) -> PosTagList:\n",
    "    return list(filter(\n",
    "        lambda x: filter_words(x, [filter_by_duplicate, filter_by_stop_word, filter_by_alphabet]),\n",
    "        words\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e865ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type: ignore\n",
    "await (get_training_data_from_folder(\"../resources/sources\", \"../resources/targets\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86d04a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Depression', 'US', 'Canada', 'National', 'Suicide', 'Prevention', 'Lifeline', 'TMS', 'TMS', 'ECT', 'ECT', 'No', 'Breastfeeding', 'Serotonin', 'Depression', 'Depression', 'PMS', 'PMDD', 'Print', 'OverviewDepression', 'Depression', 'Depression', 'Mayo', 'ClinicProducts', 'ServicesBook', 'Mayo', 'Clinic', 'Family', 'Health', 'Book', 'Mayo', 'Clinic', 'Health', 'Letter', 'Digital', 'EditionShow', 'Mayo', 'Clinic', 'SymptomsAlthough', 'Loss', 'Sleep', 'Tiredness', 'Reduced', 'Anxiety', 'Slowed', 'Frequent', 'Depression', 'Physical', 'Fatigue', 'Suicidal', 'National', 'Suicide', 'Prevention', 'Lifeline', 'Crisis', 'Line', 'InformationDepression', 'Mayo', 'ClinicMale', 'Pain', 'Show', 'Request', 'Mayo', 'Clinic', 'CausesIt', 'Brain', 'Hormones', 'Depression', 'Mayo', 'ClinicCaffeine', 'Marijuana', 'Risk', 'Certain', 'Traumatic', 'Blood', 'Being', 'History', 'Abuse', 'Certain', 'Depression', 'Pain', 'Alcohol', 'Anxiety', 'Social', 'Suicidal', 'Premature', 'InformationDepression', 'Mayo', 'ClinicDepression', 'PreventionThere', 'Mayo', 'Clinic', 'Staff', 'Depression', 'Mayo', 'Clinic', 'Request', 'Mayo', 'Clinic', 'Diagnosis', 'Print', 'Share', 'FacebookTwitter', 'Show', 'Brown', 'AY', 'Allscripts', 'EPSi', 'Mayo', 'Clinic', 'Rochester', 'Mayo', 'Clinic', 'Manual', 'Mental', 'Disorders', 'Arlington', 'American', 'Psychiatric', 'Association', 'Depression', 'National', 'Institute', 'Mental', 'Health', 'Depression', 'National', 'Alliance', 'Mental', 'Illness', 'National', 'Institute', 'Mental', 'Health', 'American', 'Psychiatric', 'Association', 'Depression', 'NIH', 'Senior', 'Health', 'Children', 'Disease', 'Control', 'Prevention', 'Depression', 'National', 'Center', 'Complementary', 'Integrative', 'Health', 'Depression', 'Natural', 'American', 'Psychological', 'Association', 'Simon', 'G', 'Stewart', 'D', 'Risks', 'SSRIs', 'Kimmel', 'MC', 'Bipolar', 'Manual', 'Mental', 'Disorders', 'Arlington', 'American', 'Psychiatric', 'Association', 'Hirsch', 'M', 'Monoamine', 'MAOIs', 'DK', 'Mayo', 'Clinic', 'Rochester', 'Krieger', 'CA', 'Mayo', 'Clinic', 'Rochester', 'Which', 'Caffeine', 'Depression', 'Depression', 'Depression', 'Depression', 'Lexapro', 'MAOIs', 'Marijuana', 'Mild', 'Monoamine', 'MAOIs', 'Natural', 'Pain', 'SSRIs', 'Serotonin', 'SNRIs', 'Tricyclic', 'Vitamin', 'Show', 'Associated', 'Procedures', 'Complete', 'CBC', 'Electroconvulsive', 'ECT', 'Psychotherapy', 'Transcranial', 'Vagus', 'Show', 'News', 'Mayo', 'Clinic', 'Science', 'Saturday', 'Mayo', 'Clinic', 'CDT', 'Products', 'Mayo', 'Clinic', 'Family', 'Health', 'Book', 'Mayo', 'Clinic', 'Health', 'Letter', 'Digital', 'Edition', 'Show', 'Mayo', 'Clinic', 'Mayo', 'Clinic', 'Rochester', 'News', 'World', 'Report', 'Learn', 'Depression', 'Symptoms', 'Mayo', 'Clinic', 'Advertisement', 'Mayo', 'Clinic', 'Advertising', 'Sponsorship', 'Policy', 'Opportunities', 'Ad', 'Choices', 'Mayo', 'Clinic', 'Press', 'Check', 'Mayo', 'Clinic', 'Try', 'Mayo', 'Clinic', 'Health', 'Letter', 'FREE', 'Back', 'Neck', 'HealthMayo', 'Clinic', 'Digestive', 'HealthNEW', 'LongerSimple', 'Home', 'Remedies', 'Patient', 'Care', 'Health', 'Information', 'Diseases', 'Conditions', 'Depression', 'Major', 'Depression', 'Diagnosis', 'Prevalence', 'Treatment', 'Medication', 'Psychotherapy', 'Pet', 'Further', 'Books', 'Diagnosis', 'Usually', 'Feeling', 'Significant', 'Feeling', 'Depression', 'Prevalence', 'Wikipedia', 'September', 'Different', 'Major', 'United', 'United', 'United', 'World', 'Health', 'Organization', 'Zhang', 'Kleinman', 'Zhang', 'China', 'Neurasthenia', 'Neurasthenia', 'Zhang', 'China', 'Neurasthenia', 'China', 'Neurasthenia', 'Typically', 'Depression', 'Children', 'Types', 'Wikipedia', 'September', 'Major', 'Melancholia', 'Chronic', 'SAD', 'Alaska', 'Canada', 'Scandinavia', 'Sweden', 'Norway', 'Denmark', 'Finland', 'Iceland', 'United', 'National', 'Health', 'Heredity', 'Serotonin', 'Alcohol', 'Treatment', 'Depression', 'Medication', 'Selective', 'SSRIs', 'Prozac', 'Paxil', 'Zoloft', 'SSRIs', 'Allegron', 'Monoamine', 'MAOIs', 'Psychotherapy', 'Psychotherapy', 'Psychotherapy', 'CBT', 'Electroconvulsive', 'ECT', 'ECT', 'Insulin', 'Lobotomy', 'Pet', 'Pet', 'Dysthymia', 'Mania', 'Bipolar', 'Cyclothymia', 'Melancholia', 'Further', 'Study', 'ADHD', 'Disorders', 'Share', 'Genetic', 'Risk', 'Factors', 'Study', 'Finds', 'New', 'York', 'Times', 'February', 'Psychiatric', 'Disorders', 'Linked', 'Genetically', 'Wall', 'Street', 'Journal', 'February', 'Resource', 'Major', 'Depressive', 'Disorder', 'PDF', 'AAPC', 'PDF', 'August', 'September', 'Depression', 'Adults', 'National', 'Mental', 'Health', 'National', 'Health', 'September', 'Suicide', 'Report', 'PDF', 'PDF', 'June', 'Child', 'Cambridge', 'Encyclopedia', 'Child', 'Development', 'Cambridge', 'University', 'Press', 'Cambridge', 'United', 'Kingdom', 'NIMH', 'Causes', 'Depression', 'July', 'July', 'Amr', 'MM', 'Halim', 'ZS', 'Moussa', 'SS', 'Environ', 'Res', 'PMID', 'Depression', 'Agricultural', 'Health', 'Study', 'Beseler', 'CL', 'Stallones', 'L', 'Hoppin', 'JA', 'Alavanja', 'MC', 'Blair', 'A', 'Keefe', 'T', 'Kamel', 'Environ', 'Health', 'Perspect', 'Dec', 'A', 'Colorado', 'Beseler', 'CL', 'Stallones', 'Ann', 'Epidemiol', 'Oct', 'Mood', 'Brazil', 'Meyer', 'A', 'Koifman', 'S', 'Koifman', 'RJ', 'Moreira', 'JC', 'Rezende', 'Chrisman', 'J', 'Y', 'J', 'Toxicol', 'Environ', 'Health', 'A', 'PMID', 'Suicide', 'Colorado', 'Stallones', 'J', 'Agromedicine', 'PMID', 'Di', 'T', 'AF', 'Villanueva', 'Forensic', 'Sci', 'Int', 'May', 'Dunn', 'Exercise', 'Depression', 'Rivals', 'Drugs', 'Therapy', 'Journal', 'Preventive', 'Medicine', 'January', 'National', 'Mental', 'Health', 'News', 'University', 'Texas', 'Southwestern', 'Medical', 'Center', 'Dallas', 'Right', 'Mayo', 'Clinic', 'Online', 'Mayo', 'Foundation', 'Medical', 'Education', 'Research', 'Understanding', 'Depression', 'Effective', 'Treatment', 'American', 'Psychological', 'Association', 'July', 'September', 'Therapy', 'ECT', 'Mayo', 'Clinic', 'Online', 'Mayo', 'Foundation', 'Medical', 'Education', 'Research', 'September', 'September', 'Brilliant', 'Madness', 'WGBH', 'PBS', 'October', 'September', 'Lobotomy', 'Andrew', 'Rosen', 'May', 'Pet', 'Therapy', 'Benefits', 'Depression', 'Anxiety', 'Major', 'Psychiatric', 'Disorders', 'Science', 'World', 'Report', 'Books', 'Books', 'Beck', 'Rush', 'Shaw', 'Emery', 'New', 'York', 'Guilford', 'Klein', 'Wender', 'New', 'York', 'Oxford', 'University', 'Press', 'Weissman', 'Markowitz', 'Klerman', 'Comprehensive', 'New', 'York', 'Books', 'Books', 'Smith', 'Jeffery', 'New', 'York', 'Point', 'Press', 'Solomon', 'Andrew', 'New', 'York', 'Sribner', 'Styron', 'William', 'Darkness', 'New', 'York', 'House', 'Wolpert', 'Lewis', 'London', 'Faber', 'Faber', 'Lewinsohn', 'Munoz', 'F', 'Youngren', 'Zeiss', 'New', 'York', 'Schuster', 'Internet', 'Mental', 'Health', 'Depressive', 'Disorder', 'Depression', 'Alliance', 'UK', 'Depression', 'Fact', 'Sheets', 'Emil', 'Kraepelin', 'Manic', 'Depression', 'Depression', 'Killer', 'Types', 'Depression', 'Treatment', 'Depression', 'Retrieved', 'Symptoms', 'Social', 'Severities', 'Grief', 'SAD', 'SAD', 'GP', 'Clinical', 'Overview', 'Symptoms', 'Causes', 'Diagnosis', 'Treatment', 'Page', 'December', 'Next', 'December', 'Depression', 'Share', 'Facebook', 'Share', 'Twitter', 'Share', 'Linkedin', 'Share', 'Pinterest', 'Share', 'Email', 'Print', 'Page', 'Mood', 'Disorders', 'Depression', 'Depression', 'Depression', 'Dysthymia', 'Depression', 'Sleep', 'Connection', 'Depression', 'PMS', 'Women', 'Lasting', 'Weight', 'Loss', 'Lasting', 'Frequent', 'Physical', 'Appropriate', 'How', 'Depression', 'Generally', 'Medication', 'Psychotherapy', 'ECT', 'Set', 'Break', 'Eat', 'Remember', 'Depression', 'Women', 'PMS', 'Depression', 'Tips', 'Bring', 'Childhood', 'Depression', 'Children', 'Grief', 'How', 'Boston', 'Children', 'Hospital', 'Department', 'Psychiatry', 'Behavioral', 'Boston', 'Children', 'Psychopharmacology', 'Clinic', 'Boston', 'Children', 'Inpatient', 'Psychiatry', 'Service', 'Depression', 'Depression', 'United', 'National', 'Institute', 'Mental', 'Health', 'United', 'Diagnostic', 'Statistical', 'Manual', 'Mental', 'Disorders', 'Fifth', 'Edition', 'Verywell', 'Report', 'Strength', 'Online', 'Therapy', 'Symptoms', 'Moderately', 'Avoiding', 'Despair', 'Difficulty', 'Difficulty', 'Excessive', 'Fatigue', 'Irritability', 'Lack', 'Low', 'Research', 'How', 'Depression', 'Every', 'Diagnosis', 'Hypothyroidism', 'American', 'Psychiatric', 'Association', 'Advice', 'Verywell', 'Mind', 'Podcast', 'Amy', 'Morin', 'LCSW', 'Verywell', 'Mind', 'Podcast', 'Olympic', 'Laurie', 'Hernandez', 'Follow', 'Apple', 'Podcasts', 'Spotify', 'Google', 'Podcasts', 'RSS', 'Differential', 'Diagnosis', 'Your', 'PMDD', 'Bipolar', 'II', 'Between', 'Moderate', 'Severe', 'Depression', 'Anhedonia', 'Causes', 'Depression', 'World', 'Health', 'Organization', 'WHO', 'Fuel', 'Depression', 'Treatments', 'Moderately', 'CBT', 'CBT', 'CBT', 'Automatic', 'DBT', 'CBT', 'IPT', 'Online', 'How', 'Best', 'Therapy', 'Depression', 'SSRIs', 'Zoloft', 'Prozac', 'Paxil', 'SSRIs', 'SNRIs', 'MAOIs', 'Food', 'Drug', 'Administration', 'FDA', 'John', 'John', 'John', 'Does', 'John', 'Wort', 'Have', 'Any', 'Drug', 'Interactions', 'Antidepressants', 'Exercise', 'Regular', 'Moderate', 'Levels', 'Stress', 'Take', 'Care', 'Yourself', 'Practicing', 'Seek', 'Engage', 'Depression', 'Substance', 'Abuse', 'Mental', 'Health', 'Administration', 'SAMHSA', 'National', 'Helpline', 'National', 'Helpline', 'Database']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32431/277962484.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cleaned_data_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../resources/targets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_by_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"depression\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"NNP\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"VBZ\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"JJ\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Parsers\n",
    "def get_cleaned_data_from_file(input_file_path: str) -> Optional[PosTagList]:\n",
    "    with open(input_file_path, \"r\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        return [tuple(row) for row in list(reader)[1:]]\n",
    "\n",
    "def get_cleaned_data_from_folder(input_path: str) -> dict[str, PosTagList]:\n",
    "    input_files = glob(input_path + \"/**/*.csv\", recursive=True)\n",
    "    \n",
    "    data = dict()\n",
    "    for file_path in input_files:\n",
    "        file_name_regex = re.compile(\"(.*)\\..*\")\n",
    "        classification_file_name = file_path.split(\"/\")[-1]\n",
    "        classification_name = file_name_regex.match(classification_file_name).group(1)\n",
    "        classification_data = get_cleaned_data_from_file(file_path)\n",
    "        data[classification_name] = classification_data\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "def group_by_tags(pos_tag_list: PosTagList) -> dict[str, list[str]]:\n",
    "    groups = dict()\n",
    "    \n",
    "    for value,tag in pos_tag_list:\n",
    "        if tag in groups:\n",
    "            groups[tag]\n",
    "            groups[tag].append(value)\n",
    "        else:\n",
    "            groups[tag] = [value]\n",
    "            \n",
    "    return groups\n",
    "    \n",
    "\n",
    "result = get_cleaned_data_from_folder(\"../resources/targets\")\n",
    "tags = group_by_tags(result[\"depression\"])\n",
    "print(tags[\"NNP\"])[:16]\n",
    "print(tags[\"VBZ\"])[:16]\n",
    "print(tags[\"JJ\"])[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39c689c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8b403e565ea1794a437a21eaf7a4df5fa78d6ee8c0957d183a6329de63bb757"
  },
  "kernelspec": {
   "display_name": "mdnlp",
   "language": "python",
   "name": "mdnlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
