{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cc7c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import asyncio\n",
    "import pyppeteer as ptr\n",
    "from typing import Optional\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "async def download_html(browser: ptr.browser.Browser, url: str, selector: str) -> Optional[str]:\n",
    "    page = await browser.newPage()\n",
    "    await page.goto(url, waitUntil=\"load\")\n",
    "    content = await page.querySelector(selector)\n",
    "\n",
    "    html = ''\n",
    "    if content:\n",
    "        html = await page.evaluate('(element) => element.textContent', content)\n",
    "\n",
    "    return html\n",
    "\n",
    "async def get_training_data_from_folder(folder_path: str) -> None:\n",
    "    browser = await ptr.launch(headless=True)\n",
    "    files = glob(folder_path + '/**/*.csv', recursive=True)\n",
    "    \n",
    "    for file in files:\n",
    "        await get_training_data(browser, file)\n",
    "        \n",
    "    await browser.close()\n",
    "\n",
    "async def get_training_data(browser: ptr.browser.Browser, file_path: str) -> None:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "\n",
    "    \n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        for _, row in df.iterrows():\n",
    "            result = await download_html(browser, row[\"link\"], row[\"selector\"])\n",
    "            await clean_up_words(await tokenize(result))\n",
    "            \n",
    "async def tokenize(data: str):\n",
    "    tokenized_words = nltk.word_tokenize(data)\n",
    "    tagged_words = nltk.pos_tag(tokenized_words)\n",
    "    return tagged_words\n",
    "\n",
    "            \n",
    "async def clean_up_words(words: list[tuple[str, str]]):\n",
    "    # Remove the stop words.\n",
    "    print(stopwords.words(\"english\"))\n",
    "    # print(words)\n",
    "    filtered_words = [word for word in words if word[0] not in stopwords.words(\"english\")]\n",
    "    # print(filtered_words)\n",
    "\n",
    "    # Remove the punctuation.\n",
    "    filterd_punctuation = [word for word in filtered_words if word[0] != word[1]]\n",
    "    print(filterd_punctuation)\n",
    "    # do nltk stuff\n",
    "    pass\n",
    "\n",
    "await (\n",
    "    get_training_data_from_folder(\"../resources/sources\")\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8b403e565ea1794a437a21eaf7a4df5fa78d6ee8c0957d183a6329de63bb757"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
